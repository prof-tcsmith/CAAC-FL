@article{baseline_study,
  title={The More is Not Always the Merrier: A Hypothesis-Driven Empirical Study of Federated Learning Aggregation Under Data Heterogeneity},
  author={[Author]},
  year={2024},
  note={Internal reference to Level 1-2 baseline study}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@inproceedings{yin2018byzantine,
  title={Byzantine-robust distributed learning: Towards optimal statistical rates},
  author={Yin, Dong and Chen, Yudong and Kannan, Ramchandran and Bartlett, Peter},
  booktitle={International Conference on Machine Learning},
  pages={5650--5659},
  year={2018},
  organization={PMLR}
}

@inproceedings{blanchard2017machine,
  title={Machine learning with adversaries: Byzantine tolerant gradient descent},
  author={Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{baruch2019little,
  title={A little is enough: Circumventing defenses for distributed learning},
  author={Baruch, Gilad and Baruch, Moran and Goldberg, Yoav},
  booktitle={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{xie2020fall,
  title={Fall of empires: Breaking byzantine-tolerant SGD by inner product manipulation},
  author={Xie, Cong and Koyejo, Sanmi and Gupta, Indranil},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={261--270},
  year={2020},
  organization={PMLR}
}

@inproceedings{fang2020local,
  title={Local model poisoning attacks to {Byzantine-Robust} federated learning},
  author={Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
  booktitle={29th USENIX Security Symposium},
  pages={1605--1622},
  year={2020}
}

@article{li2024experimental,
  title={An experimental study of Byzantine-robust aggregation schemes in federated learning},
  author={Li, Shenghui and Ngai, Edith C. H. and Voigt, Thiemo},
  journal={IEEE Transactions on Big Data},
  volume={10},
  number={6},
  pages={1--15},
  year={2024},
  publisher={IEEE}
}

@article{karimireddy2022byzantinerobust,
  title={Byzantine-robust learning on heterogeneous datasets via bucketing},
  author={Karimireddy, Sai Praneeth and He, Lie and Jaggi, Martin},
  journal={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{cao2021fltrust,
  title={{FLTrust}: Byzantine-robust federated learning via trust bootstrapping},
  author={Cao, Xiaoyu and Fang, Minghong and Liu, Jia and Gong, Neil Zhenqiang},
  booktitle={Network and Distributed System Security Symposium},
  year={2021}
}

@article{pillutla2022robust,
  title={Robust aggregation for federated learning},
  author={Pillutla, Krishna and Kakade, Sham M and Harchaoui, Zaid},
  journal={IEEE Transactions on Signal Processing},
  volume={70},
  pages={1142--1154},
  year={2022}
}

@inproceedings{reddi2021adaptive,
  title={Adaptive federated optimization},
  author={Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, H Brendan},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{hsu2019measuring,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}

@inproceedings{bagdasaryan2020backdoor,
  title={How to backdoor federated learning},
  author={Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2938--2948},
  year={2020},
  organization={PMLR}
}

@article{wang2020attack,
  title={Attack of the tails: Yes, you really can backdoor federated learning},
  author={Wang, Hongyi and Sreenivasan, Kartik and Rajput, Shashank and Vishwakarma, Harit and Aber, Saurabh and Sohn, Kwang and Lee, Dimitris and Papailiopoulos, Dimitris},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16070--16084},
  year={2020}
}

@inproceedings{shejwalkar2021manipulating,
  title={Manipulating the byzantine: Optimizing model poisoning attacks and defenses for federated learning},
  author={Shejwalkar, Virat and Houmansadr, Amir},
  booktitle={Network and Distributed System Security Symposium},
  year={2021}
}
